import joblib
from flask import Flask, request, jsonify
from flask_cors import CORS
import numpy as np
import logging
import os

# --------------------
# 1. ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
# --------------------

app = Flask(__name__)
# ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ Frontend (React) ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ API ‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡πÑ‡∏î‡πâ
CORS(app)

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Logger ‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ß‡∏•‡∏≤‡∏î‡πâ‡∏ß‡∏¢
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

model = None
le = None # Label Encoder
MODEL_CLASSES = []
MODEL_LOADED = False # ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•

# üéØ ‡πÄ‡∏û‡∏¥‡πà‡∏°: ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à (CONFIDENCE_THRESHOLD)
CONFIDENCE_THRESHOLD = 0.50 # 50%

try:
    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• SVC ‡πÅ‡∏•‡∏∞ Label Encoder (‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô Path ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á)
    model = joblib.load('svc.pkl')
    le = joblib.load('label_encoder.pkl')
    
    # ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å
    if hasattr(le, 'classes_'):
        MODEL_CLASSES = le.classes_.tolist()
    elif hasattr(model, 'classes_'):
        MODEL_CLASSES = model.classes_.tolist()
    
    app.logger.info("AI Model (svc.pkl) and Label Encoder loaded successfully.")
    app.logger.info(f"Known Classes: {MODEL_CLASSES}")
    MODEL_LOADED = True
    
except Exception as e:
    app.logger.error(f"Error loading model or label encoder: {e}")
    model = None
    le = None
    MODEL_LOADED = False

# ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Feature ‡∏ó‡∏±‡πâ‡∏á 62 ‡∏ï‡∏±‡∏ß
FEATURE_NAMES_62 = [
    "0-1","5-15","10-20","40+","45+","50+","60+","65+","<500","<800","350-550","800-2000",
    "2000-3000",">2000",">3000",">=18.5",">=25","N/a","<=2700",">=3700","120/80",">130/80",
    "<130/80",">=130/80",">140/80","95-145/80","Mass","Negligible","Overweight","M+/-","M+7Kg",
    "-M+7Kg or 10Kg","M minus 1Kg","M minus 5Kg","M minus 10Kg","M minus 0.5-1Kg","<M",
    "No change","Negligible.1","Male","Female","Wheezing","Headache","Short Breaths",
    "Rapid Breathing","Anxiety","Urine at Night","Irritability","Blurred Vision",
    "Slow Healing","Dry Mouth","Muscle Aches","Nausea/Vomiting","Insomnia","Chest Pain",
    "Dizziness","Nosebleeds","Foamy Urine","Abdominal Pain","Itchy Skin","Dark Urine",
    "Bone Pain"
]

# --------------------
# 2. API Endpoint ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏£‡∏Å (Health Check)
# --------------------
@app.route('/', methods=['GET'])
def home():
    """‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Request GET ‡πÑ‡∏õ‡∏¢‡∏±‡∏á URL ‡∏´‡∏•‡∏±‡∏Å"""
    return jsonify({
        "message": "AI Detection API Server is running.",
        "status": "online" if MODEL_LOADED else "model_error",
        "instructions": "Use the /predict endpoint with a POST request and JSON body to get a prediction."
    }), 200

# --------------------
# 3. API Endpoint ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
# --------------------

@app.route('/predict', methods=['POST'])
def predict():
    if not MODEL_LOADED:
        return jsonify({"error": "AI model or Label Encoder is not loaded."}), 500
        
    try:
        data = request.get_json()
        
        # 3.1 ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Feature Vector
        feature_vector = [data.get(name, 0) for name in FEATURE_NAMES_62]
        X = np.array(feature_vector).reshape(1, -1)
        
        # 3.2 ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™
        probas = model.predict_proba(X)[0] 
        
        # 3.3 ‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (Confidence Score) ‡πÅ‡∏•‡∏∞‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
        max_proba = np.max(probas)
        predicted_class_index = np.argmax(probas)
        
        # 3.4 ‡πÅ‡∏õ‡∏•‡∏á‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (Best Candidate)
        predicted_disease = le.inverse_transform([model.classes_[predicted_class_index]])[0]
        
        # -----------------------------------------------------------
        # üéØ ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏Å‡∏ì‡∏ë‡πå Confidence Threshold (50%)
        # -----------------------------------------------------------
        if max_proba < CONFIDENCE_THRESHOLD:
            final_prediction = "No Matching Disease"
            confidence_score = max_proba
        else:
            final_prediction = predicted_disease
            confidence_score = max_proba

        # 3.5 ‡∏™‡πà‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á Frontend
        app.logger.info(f"Prediction: {final_prediction}, Confidence: {confidence_score*100:.2f}%")
        return jsonify({
            # ‡∏™‡πà‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏£‡∏Ñ ‡∏´‡∏£‡∏∑‡∏≠ "No Matching Disease")
            "prediction": str(final_prediction), 
            # ‡∏™‡πà‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
            "probability": float(confidence_score) 
        })

    except Exception as e:
        app.logger.error(f"Prediction error: {e}")
        return jsonify({"error": f"An error occurred during prediction: {str(e)}"}), 500

# --------------------
# 4. API Endpoint ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ (Health Check)
# --------------------

@app.route('/api/wakeup', methods=['GET'])
def wakeup_server():
    """‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏•‡∏∏‡∏Å‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå Render ‡∏ó‡∏µ‡πà Sleep ‡∏≠‡∏¢‡∏π‡πà"""
    app.logger.info("Received wake-up request from frontend.")
    return jsonify({
        "message": "Server received wake-up call.",
        "status": "initializing" if not MODEL_LOADED else "online"
    }), 200
    
# ‚≠êÔ∏è Endpoint ‡πÉ‡∏´‡∏°‡πà: /api/status ‡∏ó‡∏µ‡πà Frontend ‡πÉ‡∏ä‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
@app.route('/api/status', methods=['GET'])
def check_status():
    """‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Frontend ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
    status = "online" if MODEL_LOADED else "waiting"
    app.logger.info(f"Status check requested. Status: {status}")
    return jsonify({
        "message": f"AI Server status: {status}",
        "status": status, # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ 'online' ‡∏´‡∏£‡∏∑‡∏≠ 'waiting'
        "model_loaded": MODEL_LOADED
    }), 200

# --------------------
# 5. ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô Server
# --------------------

if __name__ == '__main__':
    print("\nRegistered routes:")
    for rule in app.url_map.iter_rules():
        print(f"  {rule}")
        
    port = int(os.environ.get("PORT", 5000))
    app.run(host='0.0.0.0', port=port)
